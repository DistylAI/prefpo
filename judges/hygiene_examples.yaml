examples:
# sample 370 textgrad index 1
  - prompt: "Create a dialogue between two people who are both trying to avoid using the letter t. However, they fail, and the dialogue should still naturally include many literal t/T characters.\n\nStructure:\n- Exactly two scenes only.\n- Use plain text scene titles: write a line with \"Scene 1\" before the first scene and a line with \"Scene 2\" before the second scene (no bold/italics/markdown).\n- Separate the two scenes with exactly one separator line that contains exactly six asterisks and nothing else: ******\n  - The separator must be on its own line with no leading or trailing spaces.\n- Each spoken line must use a consistent speaker label followed by a colon, e.g., Alex: ... and Jamie: .... Use only two speakers and keep their names consistent across both scenes.\n- Do not include any other sections, summaries, notes, or counts before Scene 1 or after Scene 2.\n\nContent rules:\n- The characters intend to avoid using the letter t, but they fail and end up using many t/T characters.\n- The letter t must appear at least 30 times across both scenes (case-insensitive, counting only literal ASCII t/T). Do not substitute or obfuscate t with any other characters (no asterisks, hyphens, underscores, zero-width spaces, or lookalike letters).\n- Do not use any asterisks anywhere in the output except for the single separator line of exactly ******.\n- Keep formatting plain; no markdown, bold, italics, or decorative symbols.\n- Use natural dialogue with vocabulary likely to include t/T (e.g., treats, tarts, tea, tickets, tonight, street, little, chatter, text, notes), while staying coherent to the scene.\n- Perform a silent self-check to ensure the total count of literal t/T is \u2265 30, but do not print the count or any validation text.\n\nChecklist (for you; do not output this list):\n- Two scenes only.\n- One separator line: exactly ****** on its own line.\n- No other asterisks.\n- \u226530 literal ASCII t/T across both scenes.\n- Speaker labels with colons; plain text; no extra lines after Scene 2."
    criteria:
      - "Must give two different responses separated by 6 asterisks (******)"
      - "The letter 't' must appear at least 30 times (case-insensitive)"
    overall_reasoning: |-
      Readability: The prompt has clear section structure with labeled parts (Structure, Content rules, Checklist). The opening paragraph establishes the creative task clearly. Individual bullets are scannable. However, there is significant density—nested sub-bullets and parentheticals within bullets, The checklist at the end repeats prior information in condensed form. A reader could follow this, but it requires careful attention.
      Specification Quality: The prompt heavily over-specifies. There are many defensive clauses: "Do not substitute or obfuscate," "Do not use any asterisks anywhere... except," "Do not include any other sections." Two separate verification instructions appear: "Perform a silent self-check" and the entire "Checklist (for you; do not output this list)" section.
      Maintainability: The section labels (Structure, Content rules, Checklist) provide some modularity. However, there is substantial redundancy: the separator requirement appears in Structure and the Checklist; the t-count requirement appears in Content rules and the Checklist; the "no other asterisks" rule appears twice. The Checklist is entirely redundant—it restates everything already said. If the output fails on the separator format, you'd have to decide whether to modify the Structure bullet, the Content rules bullet about asterisks, or the Checklist item. This redundancy makes debugging unclear.
    readability_reasoning: "Clear section structure but dense within sections. Technical language and nested parentheticals. Requires careful reading."
    readability_score: 1
    spec_quality_reasoning: "Heavy over-specification beyond what criteria require. Many defensive clauses. Two verification mechanisms (silent self-check + checklist)."
    spec_quality_score: 1
    maintainability_reasoning: "Section labels help, but the Checklist is entirely redundant with prior content. Key requirements stated multiple times across sections."
    maintainability_score: 1

# sample 14 improved_2 prefpo baseline
  - prompt: "Write a short blog post about a trip to Japan. Strict word limit: under 300 words (299 words maximum). To ensure compliance and favor concision, hard-cap your response at 280 words or fewer; if you reach 280 words, stop immediately. Aim for 240\u2013270 words, and when in doubt, choose the shorter, tighter phrasing.\n\nGuidelines to stay within the limit:\n- Focus on 3\u20134 key moments (e.g., Tokyo, Kyoto, Mount Fuji, food) rather than covering everything.\n- Use concise sentences and concrete details; avoid repetition, stock phrases, and flowery filler.\n- Use 2\u20134 short paragraphs.\n- Do not include a title, headings, lists, or a word count; output only the blog post body."
    criteria:
      - "Response must have less than 300 words"
    overall_reasoning: |-
      Readability: The prompt has a clear structure: an opening task statement followed by word limit clarification and bulleted guidelines. The opening sentence is immediately understandable. The bulleted guidelines are scannable and use straightforward language.
      Specification Quality: The word count constraint is over-specified through redundancy. The prompt states "under 300 words," then "(299 words maximum)," then "hard-cap your response at 280 words or fewer," then "Aim for 240–270 words"—four different framings of essentially one constraint. The phrase "if you reach 280 words, stop immediately" is a procedural instruction telling the model how to execute unnecessarily. Some defensive clauses ("Do not include a title, headings, lists, or a word count") but not excessive.
      Maintainability: The bulleted structure provides clear organization for content guidelines—each bullet addresses a distinct aspect. However, the word count requirement appears in four different forms with four different numbers. If the output is too long or too short, it's unclear which number to adjust. The content-related bullets are well-isolated and independently modifiable. However, the word count requirement is repeated in multiple places which makes it harder to debug.
    readability_reasoning: "Clear structure with scannable bullets. Opening task is simple. The word limit section is dense with multiple numbers that require careful parsing, but individual sentences are understandable."
    readability_score: 2
    spec_quality_reasoning: "Word count is over-specified with four different numbers for one constraint. Includes unnecessary procedural instruction ('stop immediately')."
    spec_quality_score: 1
    maintainability_reasoning: "Bulleted structure helps organize content guidelines. But word count stated four different ways (300, 299, 280, 240-270) creates ambiguity about which number to adjust if output is wrong length."
    maintainability_score: 1

  - prompt: "Write a short essay about the updates of the latest episode of your favorite TV show. Use less than 300 words.\nOutput format: Output only prose (no headings, lists, quotes, italics, brackets, code blocks, or meta notes), followed by the final word count in parentheses at the very end (e.g., (198)). The parenthetical is included in the total word count, so aim lower to leave buffer.\nScope: Cover only key plot developments and character arcs from that single episode; exclude production notes (creators, directors, titles, release info), hype, and future speculation. Skip episode titles unless essential. Prefer generic referents (the team, an ally, an old friend) if proper nouns would invite production context.\nLength and structure: Target 180–220 words; hard cap 280 words including the final parenthetical; avoid hyphenations and em dashes to reduce count variance. Write 1–2 short paragraphs, maximum 6–8 simple sentences. Prefer simple declarative sentences and short clauses. Suggested flow:\n- Begin with one brief clause of prior-episode context.\n- Use 2–3 sentences for the main plot beats; stay on the central thread and avoid extra subplots.\n- Add 1 sentence that describes a central set piece/action (describe, don't evaluate).\n- Fold one short clause into an existing sentence to note a single craft element (choose tone or atmosphere, not both).\n- End with 1 sentence that gives a concise takeaway without hype or anticipation.\nStyle guardrails: Avoid intensifiers and stacked descriptors (e.g., chilling, ominous, high-stakes, tense and suspenseful), superlatives, and filler transitions. Ban scaffold phrases: As of, Notably, Meanwhile, Overall, In sum, This episode/This installment, Not only…but also. Prefer compact verbs and compress verbose phrases; mention nostalgia/genre blend at most once; do not name creators or production staff.\nPre-submit self-check: Do a quick word count, then prune in order: (1) prepositional phrases, (2) adverbs and filler transitions, (3) stacked adjectives/nominalizations, (4) redundant clauses. Limit prior-episode context to a single brief clause at the start. If over 220 words on first pass, trim and recalc; ensure the final total including the parenthetical is ≤280."
    criteria:
      - "Response must have less than 300 words"
    overall_reasoning: |-
      Readability: The prompt has visible structure with labeled sections (Output format, Scope, Length and structure, Style guardrails, Pre-submit self-check), which aids navigation. However, within each section the text is dense with many specifications packed together. Sentences contain multiple clauses and parentheticals (e.g., "avoid hyphenations and em dashes to reduce count variance"). Some language is technical or jargon-heavy ("nominalizations," "generic referents," "count variance"). The bulleted "Suggested flow" section is easier to scan, but overall a reader would need to study this carefully rather than grasp it at a glance.
      Specification Quality: The prompt heavily over-prescribes how to write the essay. It specifies exact sentence counts per section ("2-3 sentences for main plot beats," "1 sentence that describes a central set piece"), exact paragraph counts ("1-2 short paragraphs"), and even how to construct sentences ("Fold one short clause into an existing sentence"). There are extensive defensive clauses: lists of things to avoid, banned phrases, and things to exclude. The prompt includes verification instructions ("Pre-submit self-check: Do a quick word count, then prune in order...") which tell the model how to revise its own work.
      Maintainability: The labeled sections provide some modularity—you can identify that "Style guardrails" is separate from "Scope." However, the word count requirement appears in three different places with three different numbers: "less than 300 words" (opening), "Target 180-220 words" (Length section), and "hard cap 280 words" (also Length section). If the output is the wrong length, which constraint do you adjust? The "Suggested flow" bullets interact with the sentence count limits, so changing one affects interpretation of the other. The banned phrases list and style constraints overlap conceptually. A developer debugging this prompt would struggle to isolate which specific instruction caused a failure.
    readability_reasoning: "Has helpful section labels, but dense within sections; requires careful study to fully understand"
    readability_score: 1
    spec_quality_reasoning: "Extreme over-prescription of structure and style, many defensive clauses, includes self-check verification instructions"
    spec_quality_score: 0
    maintainability_reasoning: "Section labels provide some structure, but word count stated three different ways, many intertwined constraints"
    maintainability_score: 1

# sample 478 prefpo minimal improved_4
  - prompt: "Write a song for the person named 'Guerrero'. Do not include the words 'name' 'song' 'person' 'man' or 'woman' anywhere in your output in any capitalization. Do not use any commas anywhere in your response. Before returning scan and remove any commas or those words."
    criteria:
      - "Response must NOT contain any of these words (case-insensitive): name, song, person, man, woman"
      - "Response must NOT contain any commas"
    overall_reasoning: |-
      Readability: The prompt is short—just four sentences. The task is immediately clear: write a song for someone named Guerrero. The banned words list is a bit dense without proper punctuation separating each word, but still understandable. No jargon, no nested clauses, no parentheticals. Easy to read on first pass.
      Specification Quality: The core constraints are reasonable and clearly stated. However, the final sentence ("Before returning scan and remove any commas or those words") is a verification instruction which isn't completely necessary. This type of procedural self-check instruction rarely helps and adds clutter. The "Do not include" framing is slightly defensive but not excessive.
      Maintainability: The prompt is short enough that debugging would be straightforward. The banned words constraint appears once, the comma constraint appears twice—once as an instruction ("Do not use any commas") and again in the verification step ("scan and remove any commas"). This redundancy is minor given the prompt's brevity. Each constraint is separable: if output has banned words, that traces to sentence two; if output has commas, that traces to sentence three.
    readability_reasoning: "Short prompt, clear task, easy to understand. Banned words list slightly dense but understandable."
    readability_score: 2
    spec_quality_reasoning: "Includes a verification instruction ('Before returning scan and remove...') which is unnecessary. Otherwise reasonable constraints."
    spec_quality_score: 1
    maintainability_reasoning: "Short and separable constraints. Minor redundancy with comma rule appearing twice. Easy to trace failures."
    maintainability_score: 2

# sample 12 improved 13 from baseline
  - prompt: "Write a story about a man who wakes up one morning and discovers he is inside a video game.\n\nFormatting requirements (this is the only acceptance criterion; content is otherwise unrestricted):\n- Produce exactly two paragraphs of prose.\n- Separate the two paragraphs with exactly one divider line consisting of three asterisks with no spaces: *** on its own line.\n- Do not insert a blank line between paragraphs; the only separator is the *** line.\n- Do not include any other text, headings, code blocks, metadata, extra dividers, or any blank lines anywhere.\n- Each paragraph must be a single, unbroken block of text (no manual line breaks inside a paragraph).\n- The output must be exactly: paragraph 1, newline, ***, newline, paragraph 2. No leading or trailing whitespace."
    criteria:
      - "Response must have exactly 2 paragraphs separated by the markdown divider (***)"
    overall_reasoning: |-
      Readability: The prompt has a clear structure. The opening sentence is clear and immediately understandable. Each bullet is easy to scan and uses straightforward language with no jargon or dense nested clauses. The reader can understand what's being asked without re-reading.
      Specification Quality: The format itself is over-specified through redundancy rather than additional constraints also it mentions some things that aren't relevant to the story task like codeblocks and metadata. Still, the defensive clauases aren't excessive.
      Maintainability: The bulleted structure provides some organization for understanding where each instruction is located, but there is heavy overlap between the instructions.The core formatting requirement (two paragraphs separated by ***) is phrased multiple ways across different bullets. If the output has wrong formatting, it's unclear which bullet is authoritative or which to modify. This redundancy would make debugging harder than necessary.
    readability_reasoning: "Language is easy to read and understand with basically no dense sentences or awkward phrasings. Clear structure with scannable bullets."
    readability_score: 2
    spec_quality_reasoning: "The instruction is slighlty over-prescribing for a single criteria, listing things like codeblocks and metadata that aren't relevant to the story task."
    spec_quality_score: 1
    maintainability_reasoning: "Bulleted structure helps to organize but some of the instructions are repetitive for the formatting instructions which creates redundancy."
    maintainability_score: 1

  - prompt: "Write a template for a newspaper ad for a dog cage with less than 200 words. Make sure the word unfortunately appears 3 to 5 times in the ad."
    criteria:
      - "Response must have less than 200 words"
      - "The keyword 'unfortunately' must appear at least 3 times (case-insensitive)"
      - "The keyword 'unfortunately' must appear less than 6 times (case-insensitive)"
    overall_reasoning: |-
      Readability: The prompt is immediately understandable. Two sentences, each stating a clear requirement. Natural language with no jargon, nested clauses, or parentheticals. The reader knows exactly what's being asked after a single read.
      Specification Quality: The prompt specifies the goal (newspaper ad template for a dog cage) and two constraints (under 200 words, "unfortunately" 3-5 times) without overly specifying everything. No defensive clauses, no verification instructions. "Make sure" is slightly emphatic but not defensive.
      Maintainability: Each requirement is stated exactly once and is clearly separable. If the output fails any requirement, it's immediately clear which instruction to revisit. If the output is too long, the fix is obvious: adjust "less than 200 words." If "unfortunately" appears too few or too many times, the fix targets that single instruction. A developer debugging this prompt could quickly isolate which instruction caused any given failure.
    readability_reasoning: "Natural language, immediately clear, no complicated parsing required"
    readability_score: 2
    spec_quality_reasoning: "States requirements without over-specifying"
    spec_quality_score: 2
    maintainability_reasoning: "Each requirement stated once, failures easily traceable"
    maintainability_score: 2

# sample 467 textgrad index 15
  - prompt: "Write exactly one long sentence (minimum 50 words) about tax filing in a presidential, unifying, policy-forward tone, using first-person plural only (we, our)—never first-person singular (I, me, my)—and without naming or impersonating any living individual; the sentence must include at least 8 total occurrences of the letter q or Q (case-insensitive; count every q/Q anywhere in the sentence, including within required phrases), and you may use semicolons and at most one parenthetical clause to keep it a single sentence. Required inclusions: the word \"quarterly\" (e.g., \"quarterly estimated payments\"), the exact enumeration \"Q1, Q2, Q3, Q4\" (uppercase Q as shown; include it exactly once, and it may appear inside the single parenthetical), and a mention of \"Frequently Asked Questions (FAQ)\" about filing. Also include at least three distinct q-words from this list: equity or inequity/inequitable, inquiry or query, opaque, antiquated, requisite, unequivocal, quash; to help control the count and readability, avoid adding extra q-bearing words beyond these required items (note that \"Frequently Asked Questions (FAQ),\" \"quarterly,\" and \"Q1, Q2, Q3, Q4\" already contribute multiple q/Q letters). You may use one short q-alliteration set of up to three items (e.g., quickly, quietly, quite), but keep readability high. Evenly distribute q-terms across the opening, middle, and concluding parts of the sentence; do not cluster letters or use nonsense \"qqqq\" strings. Do not replace required q-words with non-q synonyms and do not remove included q-terms during refinement. Before finalizing, count q/Q and ensure the minimum is met; do not add a second parenthetical or duplicate the \"Q1, Q2, Q3, Q4\" enumeration to adjust the count. Return only the sentence—no quotes, no lists, no multiple sentences, no preface, no extra lines."
    criteria:
      - "Response must have at least 50 words"
      - "Response must be a single sentence"
      - "The letter 'q' must appear at least 8 times (case-insensitive)"
    overall_reasoning: |-
      Readability: The prompt is extremely difficult to parse. It consists of one massive paragraph with multiple long sentences packed with semicolons, em-dashes, and parentheticals. Requirements are embedded within requirements—for example, "(case-insensitive; count every q/Q anywhere in the sentence, including within required phrases)" is a nested clarification inside another clause. The reader must re-read several times to understand all the constraints.
      Specification Quality: The prompt is heavily over-prescribed. It specifies not just what to include but exactly how to include it ("evenly distribute q-terms across the opening, middle, and concluding parts"). There are numerous defensive clauses: "do not cluster letters," "do not replace required q-words," "do not remove included q-terms," "do not add a second parenthetical." The prompt includes verification instructions ("Before finalizing, count q/Q and ensure the minimum is met") which add clutter.
      Maintainability: If this prompt produces wrong output, debugging would be very difficult. The q-letter requirement appears in multiple places with slightly different framing. Instructions are intertwined—the parenthetical rule, the q-count rule, and the distribution rule all interact. The prompt is a monolithic wall of text with no logical separation or structure. If the output has the wrong number of q's, it's unclear which instruction to modify. Changing one thing risks unintended effects on other constraints.
    readability_reasoning: "Dense, legalistic language with nested clauses and parentheticals; requires multiple reads to understand; monolithic wall of text"
    readability_score: 0
    spec_quality_reasoning: "Extreme over-prescription, many defensive 'do not' clauses, includes self-verification instructions, doesn't trust the model"
    spec_quality_score: 0
    maintainability_reasoning: "Repeated requirements with different framing, heavily intertwined instructions, no logical structure, impossible to isolate which part to fix"
    maintainability_score: 0

  - prompt: "Create a detailed outline for a paper discussing the history of Yemeni coffee. Your outline should clearly list the main points and sections the paper will cover.\n\nFormatting requirements:\n- Include at least 15 distinct top-level section titles.\n- Precede each top-level section title with the literal marker \"*highlighted section* \" (including the asterisks and the trailing space), and wrap the section title itself in asterisks for markdown italics. Example: *highlighted section* *Introduction*\n- You may include optional sub-bullets under sections to indicate main points, but do not apply the \"*highlighted section* \" marker to sub-bullets and do not count them toward the 15 required sections.\n- Only top-level section titles that include the \"*highlighted section* \" marker will count toward the minimum of 15.\n- Do not provide any paragraph content—only the outline structure (headings and optional bullet points).\n\nAt the very end, add a separate line that reads: \"Highlighted sections count: N\" where N is the exact number of top-level sections you highlighted (must be >= 15). Do not include any other commentary beyond the outline and this final count line."
    criteria:
      - "Response must have at least 15 sections highlighted with markdown (e.g., *highlighted section*)"
    overall_reasoning: |-
      Readability: The prompt is well-organized with a clear two-part structure: the task (first paragraph) and the formatting requirements (bulleted list). The bullets are scannable and each addresses one aspect of the format. The example ("highlighted section Introduction") is helpful and clarifies the otherwise tricky marker syntax. Language is straightforward with no unnecessary jargon. The prompt is longer than the simplest examples but the length comes from necessary clarification of a specific format, not from verbosity.
      Specification Quality: The formatting requirements are specific, but they're specifying the actual task constraint (the marker format is what IFEval is testing). The prompt doesn't over-prescribe how to write the outline content—it leaves the actual section topics, ordering, and sub-bullet content to the model. There are a few defensive clauses ("do not apply the marker to sub-bullets," "do not count them toward the 15," "Do not provide any paragraph content"), but these feel like necessary clarifications rather than paranoid hedging. There is a verification instruction at the end (the count line) which is an issue. Overall, the specifications are appropriate for the task complexity.
      Maintainability: The bulleted structure makes requirements easy to isolate. The "15 sections" requirement appears twice (in the first bullet and the final count line), which is some repetition. Most of the bullets are independent and if there is an issue with the output, it's clear which bullet to revisit. But the last bullet is a somewhat of a catch-all and it would be unclear when an issue is detected if we should change this.
    readability_reasoning: "Well-organized with clear structure, helpful example, scannable bullets"
    readability_score: 2
    spec_quality_reasoning: "Specifications are mostly task-appropriate, but has some defensive clauses and a verification instruction"
    spec_quality_score: 1
    maintainability_reasoning: "Bulleted structure isolates requirements well, but some overlap between the instructions and there is an unclear catch-all instruction which would make debugging harder."
    maintainability_score: 1
